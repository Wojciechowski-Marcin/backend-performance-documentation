% !TeX root = ./0Base.tex

\chapter{Implementation}

%
% DOCKER
%
\section{Docker and Docker Compose}
\subsection{\acrlong{pg}}
\acrlong{pg} is built straight from the image without the need of Dockerfile, thus only the Docker Compose configuration is present. It places environment variables described in section \ref{sec:pgDbVars} from the file, creates a named volume containing the database files, reserves memory and creates a healthcheck, which allows to determine whether the container is ready to be connected to. Configuration for this service is presented in listing \ref{lst:postgresDockerCompose}
\input{listings/postgresDockerCompose.tex}

\subsection{Applications}
It made utmost sense to place this section standalone and not within each application, since the configurations for all of them are very alike.
Dockerfiles are configured to install all necessary packages, place the code in suitable folders, specify a non-root user for the container to run as and set the entrypoint to a script that starts the application.
The main differences between the Dockerfiles are the chosen images:
\begin{itemize}
    \item Django Dockerfile was inspired by Anuj Sharma, who created one for his series of Django development guide articles \cite{djangoDockerfile} - image used is python:3.9.1-slim,
    \item For Express.js, a latest slim image of \acrshort{lts} node version was chosen - node:14.17.0-slim,
    \item ASP.NET Core has a Dockerfile suggested by the documentation, so it was used in the application - images dotnet:2.1-sdk and dotnet:2.1-aspnetcore-runtime (multistage build) \cite{aspnetDockerfile}.
\end{itemize}
Dockerfiles were also checked by Hadolint, which is a linter that helps to build best practice Docker images \cite{hadolintGit}.
It verifies if the Dockerfile follows the rules presented in official docker documentation \cite{dockerBestPractices}.
Example Dockerfile is presented in listing \ref{lst:expressDockerfile}.
Docker Compose configuration points to the build folder, imports the environment variables for connection with \acrshort{pg} and variable with amount of users to create, ensures that the application starts after the database has started (makes the app wait for \acrlong{pg} healthcheck) and reserves memory for the application. To see an example of Docker Compose configuration check listing \ref{lst:expressDockerCompose}.
\input{listings/expressDockerfile.tex}
\input{listings/expressDockerCompose.tex}

\subsection{K6 and related tools}
Developers of k6 prepared instructions for usage with Docker \cite{k6RunningLocalTests}.
as well as an example Docker Compose configuration, including InfluxDB and Grafana integration \cite{k6DockerCompose}.
In the interest of the performance tests the latter was introduced, with small adjustments to fit the needs of test environment. For example, Grafana configuration was not needed in our case, since the results are later exported to a file for drawing custom graphs.

%
% DJANGO
%
\section{Django}
\subsection{Model}\label{sub:djangoModel}
Django offers a built in User model, however it was decided not to use it in this case. The reason for that is that the built in model handles extra operations for the User, like creating groups, permissions, authentication and a few additional fields. Instead of using it, the implementation of model presented in listing \ref{lst:djangoModel} was created. It does not contain the primary key definition, as django.db.models.Model class handles it automatically.
\input{listings/djangoModel.tex}

\subsection{Database connection and initialization}
Django handles a lot of things for the user - connection is very simple - in initial project generation a file settings.py is created, which consists of all the necessary variables for the system to work. In the file we can find a variable named Databases, initially with SQLite backend. All that needs to be done to connect to our \acrlong{pg} is to change the engine to built-in \acrshort{pg} backend and change the remaining fields - name, user, password, host and port, as presented in listing \ref{lst:djangoDbConn}. With that done, the connection is automatically done on the system startup.
\input{listings/djangoDbConnection.tex}
Creating the table is handled by migration system - to create the migrations the command from listing \ref{lst:djangoMakeMigrations} had to be run.
\input{listings/djangoMakeMigrations.tex}
This creates the tables based on the model presented in models.py files through the whole project. In this case, it only created one table.
For creating the initial population a management function was prepared, that is being executed from the main script. Seeding the database was presented in listing \ref{lst:djangoSeedDb}.
\input{listings/djangoSeedDb.tex}

\subsection{Routing and serialization}
Django routing is to be placed in urls.py files. There is one main file in the project configuration folder, and one in each module. Since this application consists of only one modules, two urls.py files exist - presented in listings \ref{lst:djangoUrlsConfig} and \ref{lst:djangoUrlsApp}.
\input{listings/djangoUrlsConfig.tex}
\input{listings/djangoUrlsApp.tex}
Serialization is another great thing about Django and \acrlong{drf} - \acrshort{drf} has built in abstract ModelSerializer class - to create a serializer for our model, all that needs to be done is to specify which model and which fields we want to serialize, as presented in listing \ref{lst:djangoSerialization}.
\input{listings/djangoSerialization.tex}

\subsection{Endpoints}
It is pretty certain at this point that django offers a lot of functionality. It should come with no surprise that the endpoints can also be implemented with a few lines of code, thanks to the built in methods. As shown in the listing \ref{lst:djangoViews}, creating views does not require much, only the queryset containing all user models and a serializer class.  With this ViewSet and one standalone function we get all the endpoints described in section \ref{sec:endpoints} of this document. UserViewSet class was used in the routing in file presented in listing \ref{lst:djangoUrlsApp}.
\input{listings/djangoViews.tex}

%
% EXPRESS
%
\section{Express}
\subsection{Model}
User model in express.js needs to contain all the necessary logic for handling \acrshort{crud} operations. Implementation of the model is shown in listing \ref{lst:expressModel} - it shows all \acrshort{sql} statements except include, which is placed in separate file. Database queries return \acrshort{json} object that is ready to be
\input{listings/expressModel.tex}

\subsection{Database connection and initialization}
Work with express is a bit more difficult, as most of the configuration needs to be done by the user. To connect with the database, a postgres promise instance needs to be created. Because there is no migration system, creating the table also needs to be done manually. To do so, a database configuration file was created (listing \ref{lst:expressDbConnection}) and imported into the entrypoint file. It contains all the necessary information about the connection and creation of the table.
\input{listings/expressDbConnection.tex}
Initialization of the database is handled by function presented in listing \ref{lst:expressSeedDb}.
\input{listings/expressSeedDb.tex}

\subsection{Routing and endpoints}
Unlike in Django, routes and endpoints are not separated in two files. It is very common to keep them in a single file, as shown in listing \ref{lst:expressEndpoints}. All they do is registering a route on the provided path in the first argument and executing the functions provided in the second argument. The mentioned functions call the respective method from User model sends appropriate response based on the return data of the query.
\input{listings/expressEndpoints.tex}

%
% ASP.NET
%
\section{ASP.NET}
\subsection{Model}
Model in ASP.NET Core is a class that serves a similar purpose to Django model (shown in subsection \ref{sub:djangoModel}). It defines all the fields that need to be placed in the database model, including the names, types and constraints, using \lstinline{Required} and \lstinline{Column} decorators. In addition to that, using \lstinline{JsonProperty} decorator we can describe a field name that is later used in serialization and deserialization, so we do not have to specify a serializer manually later. Model is presented in listing \ref{lst:aspnetModel}.
\input{listings/aspnetModel.tex}

\subsection{Database connection and initialization}
Connection to the database looked more similar in Express.js - we need to get all environment variables, create a connection string string using them and pass them to the \acrlong{pg} provider, as shown in listing \ref{lst:aspnetDbConnection}. Initial population generation is shown in \ref{lst:aspnetSeedDb}.
\input{listings/aspnetDbConnection.tex}
\input{listings/aspnetSeedDb.tex}

\subsection{Routing and Endpoints}
The code for controllers is quite lengthy, but that is because routing and endpoint definition is a part of database context class - using \lstinline{Route}, \lstinline{HttpGet}, \lstinline{HttpPost}, \lstinline{HttpPut} and \lstinline{HttpDelete} decorators we are able to define routes for given functions. Request parameters are placed directly into the function arguments, using \lstinline{FromQuery}, \lstinline{FromBody} clauses or by putting the argument in the decorator (for example \lstinline[mathescape]!HttpGet({id})!). All controllers can be seen in listing \ref{lst:aspnetEndpoints}.
\input{listings/aspnetEndpoints.tex}

%
% SQL
%
\section{\acrshort{sql} queries comparison}
\acrshort{sql} queries are being generated differently by ASP.NET Core and Django. In case of Express.js, it is developers role to create them, so they were prepared to try to match the queries from the other frameworks while still being relatively simple. Logs were gathered from \acrlong{pg} in a separate test with logging turned on (for performance tests logging was completely turned off).
Tables are created in the same fashion, except the primary key constraint in Django and Express.js is added right next to the definition of id field, and not separately as shown for ASP.NET in listing \ref{lst:sqlCreateTable}.
\input{listings/sqlCreateTable.tex}
ASP.NET Core uses parameterized queries (in \acrlong{pg} PREPARE and EXECUTE clauses), so log of the query is followed by parameters that the query was called with.

In get queries, presented in listing \ref{lst:sqlGet}, the interesting part to note is the LIMIT clause - it was added automatically by both ASP.NET and Django to a value bigger than 1 - this safety limit for GET requests was introduced in case provided filters in WHERE clause matched more than exactly one object (which in this case is not intended), to be able to provide a meaningful error message.

Updates and deletes (listings \ref{lst:sqlPut} and \ref{lst:sqlDelete} respectively) are preceded by select statements, that are exactly the same as in listing \ref{lst:sqlGet}.
\input{listings/sqlGet.tex}
\input{listings/sqlGetMany.tex}
\input{listings/sqlPut.tex}
\input{listings/sqlDelete.tex}
\input{listings/sqlPost.tex}

%
% PERFORMANCE
%
\section{Performance tests}
Tests implementation is divided into 6 files:
\begin{itemize}
    \item config.js,
    \item delete.test.js,
    \item get.test.js,
    \item getMany.test.js,
    \item post.test.js,
    \item put.test.js.
\end{itemize}
Configuration file config.js is a module that contains common code for all tests, utility functions such as waiting for container, preparing scenarios, parsing environment variables, creating users (in the same fashion as ones existing in the database) or exporting results to a file.

\subsection{Environment variables}
From the main script, the following test variables are passed:
\begin{itemize}
    \item TEST\_TIME - defines the length of a performance test,
    \item VU\_AMOUNT - shows with how many concurrent \acrshort{vu}s the test will be run,
    \item USER\_AMOUNT - describes amount of users existing in the database,
    \item SCENARIO - is the current scenario (according to what was said in subsection \ref{sub:scenarios}, for 1 \acrshort{vu} the scenario is constant-vus and for the other cases it is ramping-vus),
    \item FRAMEWORK - shows which framework is currently started,
    \item RESULTS\_PATH - defines a path to a file for exporting final results.
\end{itemize}

\subsection{Scenarios}
K6 have a few executors defined. For this research only two of them will be used:
\begin{itemize}
    \item Constant \acrshort{vu}s, where a fixed number of \acrlong{vu}s try to execute as many iterations as possible within a specified period of time,
    \item and Ramping \acrshort{vu}s, which is very alike to the Constant \acrshort{vu}s executor, but works on a variable number of \acrlong{vu}s \cite{k6Executors}.
\end{itemize}
To further demonstrate the meaning of code in listing \ref{lst:k6Scenarios}, it needs to be mentioned that graceful stop and graceful ramp down variables allow to finish currently running requests after the time limit has passed and stages in 'ramping-vus' case statement describe the \acrshort{vu} chart from figure \ref{fig:vusPerSecond}.
\input{listings/k6Scenarios.tex}

\subsection{Setup}
Setup function is the first user-defined thing that runs when the k6 application is started. It needs to be run from the test file, but the code that is common for all tests is shown in \ref{lst:k6Setup}. This function sends requests every 3 seconds, trying to get a response from applications' status endpoint.
\input{listings/k6Setup.tex}

\subsection{Get and delete tests}
Listing \ref{lst:k6Get} shows get test, which is the simplest of the group, so it is going to be used to explain the whole k6 test structure.
Delete test is almost the same - it differs in the request method (it sends DELETE instead of GET) and the response status checked (204 instead of 200).
Variable \lstinline{options} is used by k6 to determine scenarios for the tests and timeout for the setup function.
Setup function was mentioned in the previous subsection, it waits for the application to be started.
Handle summary function is executed at the end of the test, it is configured to export the results to the \acrshort{csv} file.
And finally default function exists to be run by the \acrshort{vu}s. Choosing the user for a request is based on two variables:
\begin{itemize}
    \item \lstinline{__VU} - identification number of the \acrshort{vu} that executes this function,
    \item and \lstinline{__ITER} - which is the number of iteration that the current \acrshort{vu} is running.
\end{itemize}
Function that chooses the id for the user is presented in listing \ref{lst:k6GetId}.
After the request is finished a status is checked for verification if the responses were correct.
Each test file contains a request function, it helped during development phase of this project, as this is the main part that is different between the tests.
Get test sends a simple GET request to the endpoint based on chosen user id.
Code common for all tests has been cut from listings \ref{lst:k6GetMany}, \ref{lst:k6Put} and \ref{lst:k6Post}.
\input{listings/k6Get.tex}
\input{listings/k6GetId.tex}

\subsection{Get many test}
Retrieving multiple users from the database operates on two variables - limit and offset. Limit was set to 100 in these tests - as presented in the chapter \ref{cha:results}, this already caused high stress for the applications compared to the other tests and allowed to create meaningful results. Offset variable changes with iteration - with each iteration next 100 rows are queried from the database. The exact methods are presented in listing \ref{lst:k6GetMany}.
\input{listings/k6GetMany.tex}

\subsection{Put test}
Put test introduce two new functions called \lstinline{getUser} and \lstinline{changeUser}. The first one, presented in listing \ref{lst:k6GetUser}, creates a user unique for given iteration of \acrshort{vu} id, and the second one, shown in listing \ref{lst:k6ChangeUser}, introduces a small change to the user - changes its username for update. What is more, a \lstinline{Content-Type} header had to be set to \lstinline{application/json}, as we are sending a \acrshort{json} content in the request.
\input{listings/k6Put.tex}
\input{listings/k6GetUser.tex}
\input{listings/k6ChangeUser.tex}

\subsection{Post test}
This test uses mentioned in the previous section function \lstinline{getUser} to create a new user in the database. Users will not collide with each other since post test starts its execution on an empty database.
\input{listings/k6Post.tex}
