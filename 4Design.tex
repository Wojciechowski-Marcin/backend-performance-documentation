% !TeX root = ./0Base.tex

\chapter{System design}\label{cha:systemDesign}

\section{Database}\label{sec:pgDbVars}

For the tests, a database consisting of a single table was created - a model is presented in a table \ref{tab:dbModel}.

\input{tables/databaseModel.tex}

For every application the operations on the \acrlong{pg} database may be slightly different, since in Django and ASP.NET they are handled by the \acrlong{orm} libraries, while Express works on SQL statements.

Database creation is based on environment variables, as it makes it easier for connecting the applications to the database later. For the connection, the following variables need to be present:
\begin{itemize}
    \item \lstinline{POSTGRES_DB}, which is the name of the database, set to postgres,
    \item \lstinline{POSTGRES_USER}, the default database user, set to postgres,
    \item \lstinline{POSTGRES_PASSWORD} as the default user password, set to postgres,
    \item \lstinline{POSTGRES_HOST} required only for applications - it is the hostname where the database can be found - because of how the docker networks work, it needs to be set to the container name - postgres,
    \item \lstinline{POSTGRES_PORT} which is the port on which the database is exposed - set to 5432
\end{itemize}

\subsection{Initial population creation}

As mentioned in subsection \ref{sub:population}, most endpoints need existing database population to work. For every application the script responsible for seeding the database looks basically the same, but for the different frameworks the piece of code had to be adjusted to three different languages. The amount of users is parameterized and can be changed on all applications by one variable in the main script, to keep the consistency between applications and avoid potential mistakes. Users are created in bulk in a single transaction to speed up the process.

Each framework (or library providing database support) has it's own built in methods for \acrshort{crud} operations, and they may be slightly different from each other. For example, Express.js and ASP.NET Core framework automatically wrap statements in a transaction. ASP.NET in each transaction sets the transaction isolation level and uses prepared statements, which then are executed with required parameters. In listings \ref{lst:aspnetPopulateLog} \ref{lst:expressPopulateLog} and \ref{lst:djangoPopulateLog} there are presented example log queries from initial user population creation.

\input{listings/aspnetPopulateLog.tex}
\input{listings/expressPopulateLog.tex}
\input{listings/djangoPopulateLog.tex}

\section{Applications endpoints}\label{sec:endpoints}

For the load tests, applications were prepared with 6 endpoints:
\begin{itemize}
    \item GET /status/
          \begin{itemize}
              \item Description: required for the script, allows to check if the server has properly started and can properly respond to requests
              \item Response code: 200
              \item Response body: empty
          \end{itemize}
    \item GET /users/\{id\}/
          \begin{itemize}
              \item Description: retrieves user with given id from the database
              \item Database operation: retrieve
              \item Parameters:
                    \begin{itemize}
                        \item id - path parameter, id of the user to be retrieved
                    \end{itemize}
              \item Response code: 200
              \item Response body: User model
          \end{itemize}
    \item GET /users/?limit=\{limit\}\&offset=\{offset\}
          \begin{itemize}
              \item Description: retrieves multiple users - allows to check the frameworks serialization speed
              \item Database operation: retrieve
              \item Parameters:
                    \begin{itemize}
                        \item limit - query parameter, amount of users returned
                        \item offset - query parameter, amount of rows to skip from the beginning
                    \end{itemize}
              \item Response code: 200
              \item Response body: User model array
          \end{itemize}
    \item DELETE /users/\{id\}/
          \begin{itemize}
              \item Description: Removes user with given id
              \item Database operation: delete
              \item Parameters:
                    \begin{itemize}
                        \item id - path parameter, id of the user to be removed
                    \end{itemize}
              \item Response code: 204
              \item Response body: empty
          \end{itemize}
    \item POST /users/
          \begin{itemize}
              \item Description: Creates user from details provided in body
              \item Database operation: create
              \item Request body: User model to be created
              \item Response code: 201
              \item Response body: User model
          \end{itemize}
    \item PUT /users/\{id\}/
          \begin{itemize}
              \item Description: Updates user with given id from details provided in body
              \item Database operation: update
              \item Request body: User model to be created
              \item Parameters:
                    \begin{itemize}
                        \item id - path parameter, id of the user to be removed
                    \end{itemize}
              \item Response code: 201
              \item Response body: User model
          \end{itemize}
\end{itemize}

"User model" mentioned above is the JSON object consisting of fields shown in table \ref{tab:dbModel}, and "User model array" is an array of these objects.

\section{Environment}

The main script prepared for this thesis, that gathers all the measurements is described in the algorithm \ref{alg:testProgress}.

\input{pseudocodes/testProgress}

Cooldown near the end of the algorithm is necessary for the CPU - all frameworks required a lot of resources and the processor increased its temperature - to avoid overheating that could result in throttling, it was decided to put a 30 seconds long cooldown. Monitoring the resources during the test proved that this was enough for the temperature to go back to normal before starting the next scenario.
